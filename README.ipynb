{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion\n",
    "\n",
    "Stable diffusion is a generative AI tech that creates and manipulates images from prompts or other images. The model uses labeled images as training data and outputs images or modification of images.  \n",
    "To use stable diffusion model, we input a text prompt, then the model outputs an image. This means Stable Diffusion has multiple models inside it.  \n",
    "Here's how it works :\n",
    "\n",
    "## The Image Layer   \n",
    "The main function of the image layer is to extract all the possible information inside an image, and encode it into a digestible format.  \n",
    "### Convolutional Network  \n",
    "Convolutional network is a type of neural network that has a 3x3 matrix (called kernel) moving to scan every area of an image to extract its features such as lines, shadows, highlights, color, saturation, etc. [[1]](https://ieeexplore.ieee.org/abstract/document/8308186) [[2]](https://arxiv.org/abs/1511.08458)  \n",
    "\n",
    "### Semantic Segmentation with U-Net  \n",
    "Semantic segmentation is a task to segment image into multiple classes and tell them what they are. This task is achieved by using convolutional network with specialized kernels. [[3]](https://ieeexplore.ieee.org/abstract/document/8354267)  \n",
    "\n",
    "![image segmentation](./assets/segmentation.png)  \n",
    "\n",
    "One of the most efficient semantic segmentation algorithm is U-Net. [[4]](https://ieeexplore.ieee.org/abstract/document/9446143)   \n",
    "\n",
    "![unet arch](./assets/unet.png)  \n",
    "\n",
    "The U-Net is trained using raw images and the images' perfect black-and-white mask as the ground truth (or target).  \n",
    "If normal convolutional models scans images in 2 dimensions (width and length), The U-Net scans images in 3 dimensions (width, length, and channels). An image consists of 3 channels, Red, Green, and Blue. Each channel can make their own monochromic image.   \n",
    "\n",
    "![rgb](./assets/rgb.png)  \n",
    "\n",
    "At the same time, U-Net also compresses the size of the image after each cycle, increasing field of view, while keeping the same kernel size, making it able to extract more and more features.  \n",
    "\n",
    "We are now at the bottom of the U curve, the model has learned all the features of the image. Now its time to scale the image back up to original size.  \n",
    "\n",
    "The U-net up-samples the image based on the image received before the image is getting compressed (hence the copy and crop grey arrow)  \n",
    "\n",
    "### U-Net as Image Denoiser  \n",
    "Because U-Net does such a good job at semantic segmentation, people are experimenting with using U-Net as an image denoiser. Noise is unwanted pixel value deviations in the image that can alter the overal perception of the image. Image denoiser's primary job is to remove noise. [[5]](https://openaccess.thecvf.com/content/ICCV2021W/NeurArch/html/Jia_DDUNet_Dense_Dense_U-Net_With_Applications_in_Image_Denoising_ICCVW_2021_paper.html)  \n",
    "\n",
    "If we generate a completely random pixels which constitutes a pure noise image, then we add a (perfect) image of fish on top of it, the result is a noised image of a fish.  \n",
    "That means, if we have a noised image of a fish, then subtract the pure noise image out of it, then we have a perfect image of a fish.   \n",
    "\n",
    "![noised fish](./assets/rgb.png)    \n",
    "\n",
    "In this image denoising model, the input is a noised image of a fish, and the ground truth is the pure noise image. However, we want to train this model in small steps. Each step, the noise going to be removed ever so slightly. Over many many steps (lets say 10, or even 1000), we will get the clean, perfect denoised image.  \n",
    "\n",
    "However, the model does not know how noisy the input image is. To do that we will use positional encoding or embedding. Positional encoding is converting discrete variables (image sequence numbers) into continuous vectors so its easily processed by the model.  \n",
    "This embedded is added into every step of the red arrow (maxpool/compression) and green arrow (upsample) as shown in the U-Net architecture.  \n",
    "\n",
    "## The Word Layer  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
